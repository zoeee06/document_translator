import io
from google.cloud import vision
import cv2
import numpy as np
from collections import Counter
from google.cloud import vision
from google.oauth2 import service_account   # â† æ–°å¢

CREDS = service_account.Credentials.from_service_account_file('service-key.json')

def ocr_image_with_line_info(image_path):
    print("æ­£åœ¨æ‰§è¡ŒOCRè¯†åˆ«(å¸¦è¡Œçº§ä¿¡æ¯)...")
    client = vision.ImageAnnotatorClient(credentials=CREDS)

    with io.open(image_path, 'rb') as image_file:
        content = image_file.read()

    image = vision.Image(content=content)
    response = client.document_text_detection(image=image)

    paragraphs = []
    for page in response.full_text_annotation.pages:
        for block in page.blocks:
            for paragraph in block.paragraphs:

                # -------- æ®µè½æ–‡æœ¬ / bbox --------
                para_text = ''.join(
                    ''.join(sym.text for sym in word.symbols)
                    for word in paragraph.words
                )
                if paragraph.bounding_box.vertices:
                    v = [(pt.x, pt.y) for pt in paragraph.bounding_box.vertices]
                    xs, ys = zip(*v)
                    para_bbox = (min(xs), min(ys), max(xs), max(ys))
                else:
                    para_bbox = (0, 0, 0, 0)

                # -------- è¡Œçº§ä¿¡æ¯ --------
                lines = []
                for word in paragraph.words:
                    if word.bounding_box.vertices:
                        v = [(pt.x, pt.y) for pt in word.bounding_box.vertices]
                        xs, ys = zip(*v)
                        line_bbox = (min(xs), min(ys), max(xs), max(ys))
                        line_txt = ''.join(sym.text for sym in word.symbols)
                        lines.append({"text": line_txt, "bounding_box": line_bbox})

                # --------ğŸ”¹ wordâ€‘level ä¿¡æ¯ --------
                words_info = []
                for word in paragraph.words:
                    if not word.bounding_box.vertices:
                        continue
                    poly = [(v.x, v.y) for v in word.bounding_box.vertices]
                    txt  = ''.join(sym.text for sym in word.symbols)
                    # åªè¦ä»»æ„å­—ç¬¦åœ¨ä¸­æ–‡ Unicode æ®µï¼Œå°±å½“ä½œä¸­æ–‡
                    is_cn = any('\u4e00' <= ch <= '\u9fff' for ch in txt)
                    words_info.append({"text": txt, "polygon": poly, "is_cn": is_cn})
                # -----------------------------------

                # 2) å†ç”¨ symbol å…œåº•ï¼ˆæŸäº›å½©è‰²å­—è¢«åˆ‡æˆå•ç‹¬ symbolï¼‰
                for word in paragraph.words:
                    for sym in word.symbols:
                        if not sym.bounding_box.vertices:
                            continue
                        txt = sym.text
                        if not any('\u4e00' <= ch <= '\u9fff' for ch in txt):
                            continue
                        poly = [(v.x, v.y) for v in sym.bounding_box.vertices]
                        words_info.append({"text": txt, "polygon": poly, "is_cn": True})

                paragraphs.append({
                    "id": f"r{len(paragraphs)+1}",  # åŠ å…¥å”¯ä¸€ID
                    "text": para_text,
                    "bounding_box": para_bbox,
                    "lines": lines,
                    "words": words_info          # <â€‘â€‘ æ–°å¢
                })

    print(f"è¯†åˆ«åˆ° {len(paragraphs)} ä¸ªæ®µè½å’Œ {sum(len(p['lines']) for p in paragraphs)} è¡Œæ–‡æœ¬")
    return paragraphs


def group_text_paragraphs(paragraphs, y_threshold=30, x_threshold=350):
    """
    æŒ‰ Y + X åŒé˜ˆå€¼åˆå¹¶ç›¸é‚»æ–‡æœ¬å—
    - y_thresholdï¼šåŒä¸€è¡Œå†…å…è®¸çš„å‚ç›´è¯¯å·®ï¼ˆåƒç´ ï¼‰
    - x_thresholdï¼šå½“ä¸¤ä¸ªæ®µè½åœ¨ X æ–¹å‘ç›¸éš”è¶…è¿‡æ­¤å€¼ï¼Œè§†ä¸ºæ–°çš„åˆ—æ®µ
    è¿”å›å€¼ä¸æ—§ç‰ˆä¸€è‡´
    """
    if not paragraphs:
        return []

    # å…ˆä¾ y è¿›è¡Œç²—æ’åº
    sorted_paras = sorted(paragraphs, key=lambda p: p["bounding_box"][1])

    grouped = []
    cur = {"text":"", "bounding_box":None, "lines": []}
    last_y = sorted_paras[0]["bounding_box"][1]
    last_x = sorted_paras[0]["bounding_box"][0]

    for para in sorted_paras:
        bx, by, bx2, by2 = para["bounding_box"]
        # æ¡ä»¶ â‘ ï¼šå‚ç›´è¶³å¤Ÿæ¥è¿‘
        same_row = abs(by - last_y) < y_threshold
        # æ¡ä»¶ â‘¡ï¼šæ°´å¹³ç›¸è·ä¸å¤§ï¼ˆé˜²æ­¢æŠŠå·¦åˆ— + å³åˆ—å¹¶åšä¸€æ®µï¼‰
        same_col = abs(bx - last_x) < x_threshold

        if same_row and same_col:
            # åˆå¹¶
            cur["text"] += para["text"]
            cur["lines"].extend(para["lines"])

            # æ›´æ–° bbox
            if cur["bounding_box"]:
                x1, y1, x2, y2 = cur["bounding_box"]
                cur["bounding_box"] = (
                    min(x1, bx), min(y1, by), max(x2, bx2), max(y2, by2)
                )
            else:
                cur["bounding_box"] = para["bounding_box"]
        else:
            # å…ˆæ”¶å°¾
            if cur["text"]:
                grouped.append(cur)
            # æ–°æ®µ
            cur = {
                "text": para["text"],
                "bounding_box": para["bounding_box"],
                "lines": para["lines"]
            }

        last_y = by
        last_x = bx

    if cur["text"]:
        grouped.append(cur)

    print(f"åˆ†ç»„åå¾—åˆ° {len(grouped)} ä¸ªè¯­ä¹‰æ®µè½")
    return grouped


